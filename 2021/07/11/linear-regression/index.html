<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/blog/libs/katex/katex.min.css"> <link rel=stylesheet  href="/blog/libs/highlight/styles/github.min.css"> <link href="/blog/css/franklin.css" rel=stylesheet > <link href="/blog/css/global.css" rel=stylesheet > <link rel=icon  href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¦¦</text></svg>"> <title>Linear Regression</title> <div class=main-nav > <nav class=flex-container > <div class=logo ><a href="https://www.jasoneveleth.com">Jason's Blog</a></div> <ul id=menu  class=flex-container > <li> <a href="/blog/">Posts</a> <li> <a href="/blog/">Search</a> <li> <a href="/blog/">Tags</a> </ul> </nav> </div> <main id=panel  class="slidout-panel slideout-panel-left"> <div class=franklin-content ><p> <details> <summary>Table of Contents</summary> </details> </p> <h1 id=theory ><a href="#theory" class=header-anchor >Theory</a></h1> <p>We are trying to find the line of best fit given a collection of coordinates. For example, \(\{(x_1, y_1), (x_2,y_2), (x_3, y_3), \dots\}\). We would like to find \(m,b\) such that \(y = mx + b\) minimizes the sum of the residuals squared. By that I mean we want to minimize a function \(L(\alpha) = \sum_i (y_i - (mx_i + b))^2\), by finding the best \(m\) and \(b\).</p> <p>We will use the notation from &#91;&#91;calculus notation|here&#93;&#93;. Here are some fun facts we&#39;ll need to know:</p> <ol> <li><p>\(\sum_i x_i^2 =\lVert x \rVert^2\)</p> <li><p>\(\lVert x \rVert^2 = x^Tx\)</p> <li><p>\((A + B)^T = A^T + B^T\) and \((AB)=B^TA^T\).</p> <li><p>\(D ( u^Tx) = u^T\), \(D (x^Tu) = u^T\), and \(D(x^Tx) = D(\bar{x}^Tx) + D(x^T\bar{x})\).<sup id="fnref:1"><a href="#fndef:1" class=fnref >[1]</a></sup></p> </ol> <p>We need to set up some definitions. Let</p> \[y = \begin{bmatrix}y_1\\y_2\\y_3\\y_4\\\vdots\end{bmatrix}, X = \begin{bmatrix}x_1 & 1\\x_2 & 1\\x_3 & 1\\x_4 & 1\\\vdots & \vdots\end{bmatrix}, \alpha = \begin{bmatrix}m\\b\end{bmatrix}.\] <p>So our goal is:</p> \[\underset{\alpha}{\text{argmin}}\, L(\alpha)\] \[=\underset{\alpha}{\text{argmin}}\, \sum ((y_i) - (m x_i + b))^2\] <p>Apply fun fact number #1:</p> \[=\underset{\alpha}{\text{argmin}}\, \left\lVert \begin{bmatrix}(y_1 - (m x_1 + b))\\(y_2 - (m x_2 + b))\\(y_3 - (m x_3 + b))\\(y_4 - (m x_4 + b))\\\vdots\end{bmatrix}\right\rVert^2\] \[=\underset{\alpha}{\text{argmin}}\, \lVert y - X\alpha\rVert^2\] <p>Apply fun fact #2:</p> \[=\underset{\alpha}{\text{argmin}}\, (y-X\alpha)^T(y - X\alpha)\] <p>Apply fun fact #3:</p> \[=\underset{\alpha}{\text{argmin}}\, (y^T - \alpha^TX^T)(y - X\alpha)\] \[=\underset{\alpha}{\text{argmin}}\, y^Ty - \alpha^TX^Ty - y^TX\alpha + \alpha^TX^TX\alpha\] <p>To minimize this, we find the critical points of the function. We do this by finding where the derivative of \(L\) with respect to \(\alpha\) is \(0\).</p> \[ \begin{align*} 0 &= L'(\alpha)\\ &= D (y^Ty - \alpha^TX^Ty - y^TX\alpha + \alpha^TX^TX\alpha)\\ &=D (y^Ty) - D (\alpha^TX^Ty) - D (y^TX\alpha) + D (\alpha^TX^TX\alpha)\\ \end{align*}\] <p>Apply fun fact #4:</p> \[ \begin{align*} &= 0 - (X^Ty)^T - y^TX + D (\alpha^TX^TX\bar{\alpha}) + D (\bar{\alpha}^TX^TX\alpha)\\ &= -y^TX - y^TX + (X^TX\alpha)^T + \alpha^TX^TX\\ &=-2y^TX + \alpha^T(X^TX)^T + \alpha^TX^TX\\ &=-2y^TX + \alpha^TX^TX + \alpha^TX^TX\\ &=-2y^TX + 2\alpha^TX^TX\\ \end{align*} \] <p>And now for the glorious part &#40;who am I kidding, this whole thing has been glorious&#41;,</p> \[2y^TX=2\alpha^TX^TX\] \[X^Ty=(X^TX)\alpha\] \[(X^TX)^{-1}X^Ty = \alpha = \begin{bmatrix}m & b\end{bmatrix}\] <h1 id=examples ><a href="#examples" class=header-anchor >Examples</a></h1> <p>Say we are given this set of coordinates: \(\{(1.3, 0.8), (3.2, 3.5), (5.6, 6.4), (8.5, 7.7)\}\). Then we can either do the arithmetic by hand &#40;from the last equation&#41; or open <code>julia</code> and give it the vectors &#40;some output omitted&#41;:</p> <pre><code class=language-julia >julia&gt; y &#61; &#91;0.8; 3.5; 6.4; 7.7&#93;
julia&gt; X &#61; &#91;1.3 1; 3.2 1; 5.6 1; 8.5 1&#93;
julia&gt; inv&#40;X&#39; * X&#41; * X&#39; * y
2-element Vector&#123;Float64&#125;:
 0.9628
 0.1228</code></pre> <p>Which gives us our desired line of best fit: \(y = 0.962823x + 0.122874\).</p> <table class=fndef  id="fndef:1"> <tr> <td class=fndef-backref ><a href="#fnref:1">[1]</a> <td class=fndef-content >The bar in \(\bar{\alpha}\) or \(\bar{x}\) means treat it as a constant, in the same way, that you would if you were doing the product rule with single-valued functions: \(D(f(x)g(x)) = D(f(x)\bar{g}(x)) + D(\bar{f}(x) g(x)) = (Df(x))g(x) + (Dg(x))f(x)\). </table> <script src="https://utteranc.es/client.js" repo="jasoneveleth/blog" issue-term=pathname  label=Comment  theme=github-light  crossorigin=anonymous  async> </script> <div class=page-foot > Â© Jason Eveleth 2023 Â· Powered by Franklin.jl Â· Last modified: July 18, 2023 </div> </div> </main> <script src="/blog/libs/katex/katex.min.js"></script> <script src="/blog/libs/katex/contrib/auto-render.min.js"></script> <script>renderMathInElement(document.body)</script> <script src="/blog/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script>